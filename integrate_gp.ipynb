{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from numpy.random import default_rng\n",
    "import warnings\n",
    "import math\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "from scipy import integrate\n",
    "import scipy.optimize as optimize\n",
    "import os\n",
    "import time\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, WhiteKernel, ConstantKernel, DotProduct\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "from scipy.stats import qmc\n",
    "import pandas as pd\n",
    "from enum import Enum\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import gpflow\n",
    "\n",
    "import itertools\n",
    "from itertools import combinations_with_replacement\n",
    "from itertools import combinations\n",
    "from itertools import permutations\n",
    "import utils\n",
    "from utils import r14, r32, r50, r125, r134a, r143a, r170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create fxn for analyzing a single gp w/ gpflow\n",
    "def eval_gp_new_theta(theta_guess, t_matrix, gp_object, Xexp):\n",
    "    #Get theta into correct form using t_matrix\n",
    "    theta_guess = theta_guess.reshape(1,-1)\n",
    "    gp_theta = theta_guess@t_matrix.T\n",
    "    #Append x data for consideration\n",
    "    gp_theta = np.repeat(gp_theta, len(Xexp) , axis = 0)\n",
    "    gp_input = np.concatenate((gp_theta, Xexp), axis=1)\n",
    "    #Get mean and std from gp\n",
    "    gp_mean, gp_covar = gp_object.predict_f(gp_input, full_cov=True)\n",
    "    gp_std = np.sqrt(np.diag(gp_covar))\n",
    "    \n",
    "    return gp_mean, gp_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sim_liq_density': <gpflow.models.gpr.GPR object at 0x7f7a5ccdc650>, 'sim_vap_density': <gpflow.models.gpr.GPR object at 0x7f79d0648310>, 'sim_Pvap': <gpflow.models.gpr.GPR object at 0x7f79d0631dd0>, 'sim_Hvap': <gpflow.models.gpr.GPR object at 0x7f79d0646650>}\n"
     ]
    }
   ],
   "source": [
    "with open(\"R14-vlegp/vle-gps.pkl\", 'rb') as pickle_file:\n",
    "    data = pickle.load(pickle_file)\n",
    "\n",
    "print(data)\n",
    "# gpflow.utilities.print_summary(data)\n",
    "# import tensorflow as tf\n",
    "# for i, model in enumerate(list(data.values())):\n",
    "#     print(list(data.keys())[i])\n",
    "#     gpflow.utilities.print_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify initial guesse\n",
    "#Set repeats\n",
    "repeats = 50\n",
    "\n",
    "#TODO:\n",
    "#Make file in utils for atom types\n",
    "    #class transform_matricies\n",
    "        #__init__(self, param_bounds, param_names, dict_of_matricies)\n",
    "        #Give it a dictionary of tansformation matricies for each molecule class in utils.py\n",
    "        #Method set_transfor_matrix(R14Constantsclass)\n",
    "\n",
    "#Get bounds for atom typing scheme (from NW for now)\n",
    "at_param_bounds_l = [2, 1.5, 2, 10, 2, 15]\n",
    "at_param_bounds_u = [4,   3, 4, 75,10, 50]\n",
    "at_param_bounds = np.array([at_param_bounds_l, at_param_bounds_u]).T\n",
    "\n",
    "#Load class properies for each molecule\n",
    "r14 = utils.r14.R14Constants\n",
    "r32 = utils.r32.R32Constants\n",
    "r50 = utils.r50.R50Constants\n",
    "r125 = utils.r125.R125Constants\n",
    "r134a = utils.r134a.R134aConstants\n",
    "r143a = utils.r143a.R143aConstants\n",
    "r170 = utils.r170.R170Constants\n",
    "\n",
    "#Get dict of refrigerants to consider\n",
    "molec_data_dict = {\"r14\":r14,\n",
    "                \"r32\":r32,\n",
    "                \"r50\":r50,\n",
    "                \"r125\":r125,\n",
    "                \"r134a\":r134a,\n",
    "                \"r143a\":r143a,\n",
    "                \"r170\":r170}\n",
    "#For each molecule, append the MD density gp to the VLE density gp dictionary w/ key \"MD Density\"\n",
    "#Make a dict of these gp dictionaries for each molecule\n",
    "\n",
    "#define the scipy function for minimizing\n",
    "def scipy_min_fxn(theta_guess, molec_data_dict, molec_gp_dict):\n",
    "    #Initialize weight and squared error arrays\n",
    "    sqerr_array  = []\n",
    "    weight_array = []\n",
    "\n",
    "    #Loop over molecules\n",
    "    for molec in molec_data_dict.keys():\n",
    "        #Get theta associated with each gp\n",
    "        param_matrix = AT(7, molec)\n",
    "        #Get number of GPs for each molecule\n",
    "        all_gps_dict = molec_gp_dict[molec].values()\n",
    "        #Loop over number of GPs\n",
    "        for gp_model in all_gps_dict.values():\n",
    "            #Get X and Y data associated with each GP\n",
    "        \n",
    "            #Evaluate GP\n",
    "            gp_mean, gp_std = eval_gp_new_theta(theta_guess, param_matrix, gp_model, xexp)\n",
    "            #Calculate weight from uncertainty\n",
    "            weight_mpi = (1/(gp_std**2)).tolist()\n",
    "            weight_array += weight_mpi\n",
    "            #Calculate sse\n",
    "            sq_err = ((yexp.flatten() - gp_mean)**2).tolist()\n",
    "            sqerr_array += sq_err\n",
    "    #List to array\n",
    "    sqerr_array = np.array(sqerr_array)\n",
    "    weight_array = np.array(weight_array)\n",
    "    #Normalize weights to add up to 1\n",
    "    scaled_weights = weight_array / np.sum(weight_array)\n",
    "    #Define objective function\n",
    "    obj = np.sum(scaled_weights*sqerr_array)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify initial guesses bounds for new_theta\n",
    "repeats = 50\n",
    "bounds_theta_new_l = [-5, -5, -5, -5, -5]\n",
    "bounds_theta_new_u = [ 2,  2,  2,  2,  2]\n",
    "bounds_theta_new = np.array([bounds_theta_new_l, bounds_theta_new_u]).T\n",
    "theta_guesses = np.random.uniform(low=bounds_theta_new_l, high=bounds_theta_new_u, size=(repeats, len(bounds_theta_new_l)) )\n",
    "\n",
    "#Define matricies, gps, and data to look at\n",
    "t_matricies = [t_matrix, t_matrix2]\n",
    "gps = [fit_gp_model, fit_gp_model2]\n",
    "Xexp_list = [Xexp, Xexp2]\n",
    "Yexp_list = [Yexp, Yexp2]\n",
    "\n",
    "#Initialize results dataframe\n",
    "column_names = ['Theta Guess', 'Min Obj', 'Param at Min Obj', 'Min Obj Cum.', 'Param at Min Obj Cum.',\n",
    "                \"func evals\", \"jac evals\", \"Termination\", \"Total Run Time\"]\n",
    "ls_results = pd.DataFrame(columns=column_names)\n",
    "\n",
    "#Optimize w/ retstarts\n",
    "for i in range(repeats):\n",
    "    #Start timer\n",
    "    time_start = time.time()\n",
    "    #Get guess and find scipy.optimize solution\n",
    "    Solution = optimize.minimize(scipy_min_fxn, theta_guesses[i] , bounds=bounds_theta_new, method='L-BFGS-B', \n",
    "                                 args=(t_matricies, gps, Xexp_list, Yexp_list), options = {\"disp\":False})\n",
    "    #End timer and calculate total run time\n",
    "    time_end = time.time()\n",
    "    time_per_run = time_end-time_start\n",
    "    #Back out results\n",
    "    param_min_obj = Solution.x\n",
    "    min_obj = Solution.fun\n",
    "    \n",
    "    #Create df for each least squares run\n",
    "    iter_df = pd.DataFrame(columns=column_names)\n",
    "    #On 1st iteration, min obj cum and theta min obj cum are the same as sse and sse min obj\n",
    "    if i == 0:\n",
    "        ls_iter_res = [theta_guesses[i], min_obj, param_min_obj, min_obj, param_min_obj, Solution.nfev, \n",
    "                            Solution.njev, Solution.status, time_per_run]\n",
    "    #Otherwise compare to the iteration before before setting\n",
    "    else:\n",
    "        obj_cum = min_obj if min_obj < ls_results[\"Min Obj Cum.\"].iloc[i-1] else ls_results[\"Min Obj Cum.\"].iloc[i-1]\n",
    "        theta_obj_cum = param_min_obj if min_obj < ls_results[\"Min Obj Cum.\"].iloc[i-1] else ls_results['Param at Min Obj Cum.'].iloc[i-1]\n",
    "        ls_iter_res = [theta_guesses[i], min_obj, Solution.x, obj_cum, theta_obj_cum,  Solution.nfev, \n",
    "                            Solution.njev, Solution.status, time_per_run]\n",
    "\n",
    "    # Add the new row to the DataFrame\n",
    "    iter_df.loc[0] = ls_iter_res\n",
    "    ls_results = pd.concat([ls_results.astype(iter_df.dtypes), iter_df], ignore_index=True)\n",
    "\n",
    "print(ls_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atom_type",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
