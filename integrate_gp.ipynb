{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_928623/3564762054.py:15: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "2024-02-08 12:36:55.249712: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-08 12:36:55.307434: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-08 12:36:55.307497: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-08 12:36:55.309579: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-08 12:36:55.319409: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-08 12:36:55.320453: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-08 12:36:56.807201: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as optimize\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import gpflow\n",
    "\n",
    "import utils\n",
    "from utils import r14, r32, r50, r125, r134a, r143a, r170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create fxn for analyzing a single gp w/ gpflow\n",
    "def eval_gp_new_theta(theta_guess, t_matrix, gp_object, Xexp):\n",
    "    #Get theta into correct form using t_matrix\n",
    "    theta_guess = theta_guess.reshape(1,-1)\n",
    "    gp_theta = theta_guess@t_matrix.T\n",
    "    #Append x data for consideration\n",
    "    gp_theta = np.repeat(gp_theta, len(Xexp) , axis = 0)\n",
    "    gp_input = np.concatenate((gp_theta, Xexp), axis=1)\n",
    "    #Get mean and std from gp\n",
    "    gp_mean, gp_covar = gp_object.predict_f(gp_input, full_cov=True)\n",
    "    gp_std = np.sqrt(np.diag(gp_covar))\n",
    "    \n",
    "    return gp_mean, gp_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{130: 142.0, 150: 131.72, 170: 118.77, 190: 101.5, 210: 75.63}\n"
     ]
    }
   ],
   "source": [
    "#Load class properies for each molecule\n",
    "r14 = r14.R14Constants()\n",
    "r32 = r32.R32Constants()\n",
    "r50 = r50.R50Constants()\n",
    "r125 = r125.R125Constants()\n",
    "r134a = r134a.R134aConstants()\n",
    "r143a = r143a.R143aConstants()\n",
    "r170 = r170.R170Constants()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#Get dict of refrigerants to consider\n",
    "molec_data_dict = {\"R14\":r14,\n",
    "                \"R32\":r32,\n",
    "                \"R50\":r50,\n",
    "                \"R125\":r125,\n",
    "                \"R134a\":r134a,\n",
    "                \"R143a\":r143a,\n",
    "                \"R170\":r170}\n",
    "\n",
    "#Make a dict of the gp dictionaries for each molecule\n",
    "all_gp_dict = {}\n",
    "#loop over molecules\n",
    "for key in list(molec_data_dict.keys()):\n",
    "    #Get dict of vle gps\n",
    "    #OPTIONAL append the MD density gp to the VLE density gp dictionary w/ key \"MD Density\"\n",
    "     file = os.path.join(key +\"-vlegp/vle-gps.pkl\")\n",
    "     with open(file, 'rb') as pickle_file:\n",
    "        all_gp_dict[key] = pickle.load(pickle_file)\n",
    "\n",
    "#define the scipy function for minimizing\n",
    "def scipy_min_fxn(theta_guess, molec_data_dict, all_gp_dict):\n",
    "    #Initialize weight and squared error arrays\n",
    "    sqerr_array  = []\n",
    "    weight_array = []\n",
    "\n",
    "    #Loop over molecules\n",
    "    for molec in list(molec_data_dict.keys()):\n",
    "        #Get theta associated with each gp\n",
    "        # param_matrix = AT(7, molec)\n",
    "        #Get GPs associated with each molecule\n",
    "        molec_gps_dict = all_gp_dict[molec]\n",
    "        #Loop over gps (1 per property)\n",
    "        for key in list(molec_gps_dict.keys()):\n",
    "            #Get GP associated with property\n",
    "            gp_model = molec_gps_dict[key]\n",
    "            #Get X and Y data associated with the GP\n",
    "            if \"vap_density\" in key:\n",
    "                exp_data = molec_data_dict[molec].expt_vap_density\n",
    "            elif \"liq_density\" in key:\n",
    "                exp_data = molec_data_dict[molec].expt_liq_density\n",
    "            elif \"Pvap\" in key: \n",
    "                exp_data = molec_data_dict[molec].expt_Pvap\n",
    "            elif \"Hvap\" in key:\n",
    "                exp_data = molec_data_dict[molec].expt_Hvap\n",
    "            else:\n",
    "                raise(ValueError, \"all_gp_dict must contain a dict with keys sim_vap_density, sim_liq_density, sim_Hvap, or, sim_Pvap\")\n",
    "            #Get x and y data\n",
    "            x_exp = np.array(list(exp_data.keys())).reshape(-1,1)\n",
    "            y_exp = np.array(list(exp_data.values()))\n",
    "\n",
    "            # #Evaluate GP\n",
    "            # gp_mean, gp_std = eval_gp_new_theta(theta_guess, param_matrix, gp_model, x_exp)\n",
    "            # #Calculate weight from uncertainty\n",
    "            # weight_mpi = (1/(gp_std**2)).tolist()\n",
    "            # weight_array += weight_mpi\n",
    "            # #Calculate sse\n",
    "            # sq_err = ((y_exp.flatten() - gp_mean)**2).tolist()\n",
    "            # sqerr_array += sq_err\n",
    "    \n",
    "    #List to array\n",
    "    sqerr_array = np.array(sqerr_array)\n",
    "    weight_array = np.array(weight_array)\n",
    "    #Normalize weights to add up to 1\n",
    "    scaled_weights = weight_array / np.sum(weight_array)\n",
    "    #Define objective function\n",
    "    obj = np.sum(scaled_weights*sqerr_array)\n",
    "    return obj\n",
    "\n",
    "#Check output\n",
    "print(scipy_min_fxn(1, molec_data_dict, all_gp_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify initial guesse\n",
    "#Set repeats\n",
    "repeats = 50\n",
    "\n",
    "#TODO:\n",
    "#Make file in utils for atom types\n",
    "    #class transform_matricies\n",
    "        #__init__(self, param_bounds, param_names, dict_of_matricies)\n",
    "        #Give it a dictionary of tansformation matricies for each molecule class in utils.py\n",
    "        #Method set_transfor_matrix(R14Constantsclass)\n",
    "\n",
    "#Get bounds for atom typing scheme (from NW for now)\n",
    "at_param_bounds_l = [2, 1.5, 2, 10, 2, 15]\n",
    "at_param_bounds_u = [4,   3, 4, 75,10, 50]\n",
    "at_param_bounds = np.array([at_param_bounds_l, at_param_bounds_u]).T\n",
    "#Get initial guesses\n",
    "param_inits = np.random.uniform(low=at_param_bounds_l, high=at_param_bounds_u, size=(repeats, len(at_param_bounds_l)) )\n",
    "#Initialize results dataframe\n",
    "column_names = ['Param Init', 'Min Obj', 'Param at Min Obj', 'Min Obj Cum.', 'Param at Min Obj Cum.',\n",
    "                \"func evals\", \"jac evals\", \"Termination\", \"Total Run Time\"]\n",
    "ls_results = pd.DataFrame(columns=column_names)\n",
    "\n",
    "#Optimize w/ retstarts\n",
    "for i in range(repeats):\n",
    "    #Start timer\n",
    "    time_start = time.time()\n",
    "    #Get guess and find scipy.optimize solution\n",
    "    Solution = optimize.minimize(scipy_min_fxn, param_inits[i] , bounds=at_param_bounds, method='L-BFGS-B', \n",
    "                                 args=(molec_data_dict, all_gp_dict), options = {\"disp\":False})\n",
    "    #End timer and calculate total run time\n",
    "    time_end = time.time()\n",
    "    time_per_run = time_end-time_start\n",
    "    #Back out results\n",
    "    param_min_obj = Solution.x\n",
    "    min_obj = Solution.fun\n",
    "    \n",
    "    #Create df for each least squares run\n",
    "    iter_df = pd.DataFrame(columns=column_names)\n",
    "    #On 1st iteration, min obj cum and theta min obj cum are the same as sse and sse min obj\n",
    "    if i==0 or min_obj < ls_results[\"Min Obj Cum.\"].iloc[i-1]:\n",
    "        obj_cum = min_obj  \n",
    "        theta_obj_cum = param_min_obj\n",
    "    else:\n",
    "        obj_cum = ls_results[\"Min Obj Cum.\"].iloc[i-1]\n",
    "        theta_obj_cum = ls_results['Param at Min Obj Cum.'].iloc[i-1]\n",
    "\n",
    "    ls_iter_res = [param_inits[i], min_obj, Solution.x, obj_cum, theta_obj_cum,  Solution.nfev, \n",
    "                        Solution.njev, Solution.status, time_per_run]\n",
    "\n",
    "    # Add the new row to the DataFrame\n",
    "    iter_df.loc[0] = ls_iter_res\n",
    "    ls_results = pd.concat([ls_results.astype(iter_df.dtypes), iter_df], ignore_index=True)\n",
    "\n",
    "print(ls_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atom_type",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
