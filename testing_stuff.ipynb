{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-19 14:34:42.515074: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-19 14:34:42.561204: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-19 14:34:42.561260: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-19 14:34:42.562742: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-19 14:34:42.570112: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-19 14:34:42.570586: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-19 14:34:47.544373: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from utils.molec_class_files import r14, r32, r50, r125, r134a, r143a, r170, r41, r23, r161, r152a, r152, r134, r143, r116\n",
    "from utils import atom_type, opt_atom_types\n",
    "import numpy as np\n",
    "import unyt as u\n",
    "import pandas as pd\n",
    "from fffit.fffit.utils import values_real_to_scaled, values_scaled_to_real, variances_scaled_to_real, generate_lhs\n",
    "from fffit.fffit.plot import plot_obj_contour\n",
    "import os\n",
    "\n",
    "#Load class properies for each molecule\n",
    "r14_class = r14.R14Constants()\n",
    "r32_class = r32.R32Constants()\n",
    "r50_class = r50.R50Constants()\n",
    "r125_class = r125.R125Constants()\n",
    "r134a_class = r134a.R134aConstants()\n",
    "r143a_class = r143a.R143aConstants()\n",
    "r170_class = r170.R170Constants()\n",
    "\n",
    "r41_class = r41.R41Constants()\n",
    "r23_class = r23.R23Constants()\n",
    "r161_class = r161.R161Constants()\n",
    "r152a_class = r152a.R152aConstants()\n",
    "r152_class = r152.R152Constants()\n",
    "r143_class = r143.R143Constants()\n",
    "r134_class = r134.R134Constants()\n",
    "r116_class = r116.R116Constants()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "values = np.array([1,2,3,4,5])\n",
    "print(values[:1])\n",
    "sets = np.array([[0,0,0],\n",
    "                [1,1,1],\n",
    "                [1,1,1],\n",
    "                [1,0.5,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2\n",
      "0  0.0  0.0  0.0\n",
      "1  1.0  0.5  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "def filter_unique_sets(sets, threshold=0.01):\n",
    "    # Compute the pairwise Euclidean distances\n",
    "    distances = pdist(sets, metric='euclidean')\n",
    "    distance_matrix = squareform(distances)\n",
    "\n",
    "    # Initialize a boolean array to keep track of unique sets\n",
    "    unique_mask = np.ones(sets.shape[0], dtype=bool)\n",
    "\n",
    "    # Iterate over the upper triangle of the distance matrix\n",
    "    for i in range(sets.shape[0]):\n",
    "        # If the current set is already marked as non-unique, skip it\n",
    "        if not unique_mask[i]:\n",
    "            continue\n",
    "        # Mark sets within the threshold distance as non-unique\n",
    "        within_threshold = distance_matrix[i] <= threshold\n",
    "        unique_mask[within_threshold] = False\n",
    "        unique_mask[i] = True  # Keep the current set\n",
    "\n",
    "    return sets[unique_mask]\n",
    "\n",
    "# Example usage:\n",
    "sets = np.array([\n",
    "    [0, 0, 0],\n",
    "    [1, 1, 1],\n",
    "    [1, 1, 1],\n",
    "    [1, 0.5, 1]])\n",
    "\n",
    "print(filter_unique_sets(sets))\n",
    "\n",
    "def get_unique_sets(self, all_param_sets, save_data = False, save_label = None):\n",
    "        \"\"\"\n",
    "        Gets unique sets of parameters from an array of parameters\n",
    "        \n",
    "        \"\"\"\n",
    "        assert isinstance(save_data, bool), \"save_data must be a bool\"\n",
    "        assert isinstance(save_label, (str, type(None))), \"save_label must be a string or None\"\n",
    "        #Scale values from preferred to real units\n",
    "        all_param_sets_real = self.values_pref_to_real(all_param_sets)\n",
    "        #Scale values between 0 and 1 with minmax scaler\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(self.at_class.at_bounds_nm_kjmol.T)\n",
    "        all_param_sets_scaled = scaler.transform(all_param_sets_real)\n",
    "        #Calculate the scaled euclidean distance between each pair of scaled points\n",
    "        dist = pdist(all_param_sets_scaled)/np.sqrt(all_param_sets.shape[1])\n",
    "        #Convert the condensed distance matrix to square form\n",
    "        dist_sq = squareform(dist)\n",
    "        #Fill diagonals w/ infinity\n",
    "        np.fill_diagonal(dist_sq, np.inf)\n",
    "        # Find the indices of points where all distances to other points (excluding diagonal) are greater than 0.01\n",
    "        valid_indices = np.where(np.all(dist_sq > 0.01, axis=1))[0]\n",
    "        if len(valid_indices) > 0:\n",
    "            unique_param_sets = all_param_sets[valid_indices]\n",
    "        else:\n",
    "            unique_param_sets = all_param_sets[0].reshape(1,-1)\n",
    "\n",
    "        data_df = pd.DataFrame(unique_param_sets, columns=self.at_class.at_names)\n",
    "\n",
    "        if save_data == True:\n",
    "            save_label = save_label if save_label is not None else \"test_set\"\n",
    "            save_csv_path = os.path.join(self.use_dir_name, \"unique_\" + save_label + \".csv\")\n",
    "            data_df.to_csv(save_csv_path, index = False, header = True)\n",
    "\n",
    "        return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.8239609   3.39920875  3.8546543   3.33491516  3.89283056  3.639822\n",
      "   2.0802739   3.27818297  2.82286278  2.94406375  2.92954002 55.18038398\n",
      "  42.25299831 44.52003378 64.60461016 23.16107594 38.57869402 10.34133395\n",
      "  31.32968437 42.44898523 22.10720589 28.52377367]\n",
      " [ 3.82754911  3.39798447  3.85549928  3.33258007  3.89432735  3.63465496\n",
      "   2.07673867  3.29733467  2.82270312  2.94353075  2.92961987 55.4788963\n",
      "  42.30334122 44.65694564 65.05272146 23.15428879 38.5826963  10.30499307\n",
      "  31.32274285 42.44767029 22.19684474 28.52768862]\n",
      " [ 3.82533802  3.39763371  3.85552511  3.33361125  3.89140049  3.63812591\n",
      "   2.07605843  3.28491134  2.82278166  2.94461944  2.92961392 55.41485728\n",
      "  42.29773532 44.65670806 65.11913255 23.2843161  38.43964866 10.32362972\n",
      "  31.07092867 42.42104229 22.17778174 28.53608863]\n",
      " [ 3.82577359  3.39794495  3.85452641  3.3407888   3.88913186  3.63039545\n",
      "   2.07414236  3.26305209  2.82301276  2.94730451  2.92963941 55.46630129\n",
      "  42.30975767 44.67950372 64.09106775 23.30409499 39.04438061 10.32786895\n",
      "  31.43739354 42.40170425 22.08039422 28.52571954]]\n"
     ]
    }
   ],
   "source": [
    "#Get obj from a set of parameters\n",
    "import copy\n",
    "# at_class = atom_type.AT_Scheme_11()\n",
    "save_data = True\n",
    "obj_choice = \"ExpVal\"\n",
    "molec_names = [\"R14\", \"R32\", \"R50\", \"R170\", \"R125\", \"R134a\", \"R143a\"] \n",
    "at_number = 11\n",
    "problem_setup = opt_atom_types.Problem_Setup(molec_names, at_number, obj_choice)\n",
    "\n",
    "#Best set from Experiment\n",
    "#Set parameter set of interest (in this case get the best parameter set)\n",
    "all_molec_dir = problem_setup.use_dir_name\n",
    "path_best_sets = os.path.join(all_molec_dir, \"best_per_run.csv\")\n",
    "assert os.path.exists(path_best_sets), \"best_per_run.csv not found in directory\"\n",
    "all_df = pd.read_csv(path_best_sets, header = 0)\n",
    "first_param_name = problem_setup.at_class.at_names[0] + \"_min\"\n",
    "last_param_name = problem_setup.at_class.at_names[-1] + \"_min\"\n",
    "best_set = all_df.loc[:3, first_param_name:last_param_name].values\n",
    "best_real = problem_setup.values_pref_to_real(copy.copy(best_set))\n",
    "best_pref = problem_setup.values_real_to_pref(copy.copy(best_real))\n",
    "print(best_pref)\n",
    " #Unscale data from 0 to 1 to get correct objective values\n",
    "at_bounds_pref = problem_setup.at_class.at_bounds_nm_kjmol\n",
    "theta_guess = values_real_to_scaled(best_real.reshape(-1,22), at_bounds_pref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeats = 1\n",
    "seed =1\n",
    "setup = opt_atom_types.Opt_ATs(molec_data_dict, all_gp_dict, at_class, repeats, seed, obj_choice)\n",
    "rank_parameters, n_data = setup.rank_parameters(best_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the parameter name asociated with each index of rank_parameters\n",
    "rank_parameters_names = [problem_setup.at_class.at_names[i] for i in rank_parameters]\n",
    "print(rank_parameters_names)\n",
    "print(n_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_num_params, rcc, loss_k, loss_k_params = setup.estimate_opt(theta_guess, rank_parameters, n_data)\n",
    "print(\"Optimal number of parameters: \", opt_num_params)\n",
    "print(\"RCC: \", rcc)\n",
    "print(\"Best Param Set: \", loss_k_params[opt_num_params-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numdifftools as nd\n",
    "fun = lambda x: problem_setup.calc_fxn(x)\n",
    "dfun = nd.Gradient(fun)\n",
    "gradient = dfun([theta_guess])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_scl = gradient*theta_guess\n",
    "print(gradient_scl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from scipy.linalg import lstsq\n",
    "\n",
    "def rank_parameters(Z):\n",
    "    # Step 1: Calculate the magnitude of each column in Z\n",
    "    column_magnitudes = norm(Z, axis=0)\n",
    "    \n",
    "    # Initialize variables\n",
    "    ranked_indices = []  # To keep track of ranked parameter indices\n",
    "    k = 1\n",
    "    n, m = Z.shape\n",
    "\n",
    "    while k <= m:\n",
    "        if k == 1:\n",
    "            # Step 2: Identify the most estimable parameter\n",
    "            max_index = np.argmax(column_magnitudes)\n",
    "            ranked_indices.append(max_index)\n",
    "        else:\n",
    "            # Step 3: Build X_k with the k most estimable columns\n",
    "            X_k = Z[:, ranked_indices]\n",
    "\n",
    "            # Predict Z using ordinary least-squares\n",
    "            Z_hat, _, _, _ = lstsq(X_k, Z)\n",
    "\n",
    "            # Calculate the residual matrix R_k\n",
    "            R_k = Z - X_k @ Z_hat\n",
    "\n",
    "            # Step 4: Calculate the magnitude of each column in R_k\n",
    "            residual_magnitudes = norm(R_k, axis=0)\n",
    "\n",
    "            # Step 5: Determine the next most estimable parameter\n",
    "            # Ensure we pick a column that hasn't been ranked yet\n",
    "            for idx in np.argsort(-residual_magnitudes):\n",
    "                if idx not in ranked_indices:\n",
    "                    ranked_indices.append(idx)\n",
    "                    break\n",
    "        \n",
    "        k += 1  # Step 6: Increase k and repeat\n",
    "\n",
    "    return ranked_indices\n",
    "\n",
    "# Example usage\n",
    "Z = gradient_scl\n",
    "ranked_params = rank_parameters(Z)\n",
    "print(\"Ranked parameters (indices):\", ranked_params)\n",
    "value = [at_class.at_names[param] for param in ranked_params]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hfcs-fffit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
