{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.molec_class_files import r14, r32, r50, r125, r134a, r143a, r170, r41, r23, r161, r152a, r152, r134, r143, r116\n",
    "from utils import atom_type, opt_atom_types\n",
    "import numpy as np\n",
    "import unyt as u\n",
    "import pandas as pd\n",
    "from fffit.fffit.utils import values_real_to_scaled, values_scaled_to_real, variances_scaled_to_real, generate_lhs\n",
    "from fffit.fffit.plot import plot_obj_contour\n",
    "import os\n",
    "\n",
    "#Load class properies for each molecule\n",
    "r14_class = r14.R14Constants()\n",
    "r32_class = r32.R32Constants()\n",
    "r50_class = r50.R50Constants()\n",
    "r125_class = r125.R125Constants()\n",
    "r134a_class = r134a.R134aConstants()\n",
    "r143a_class = r143a.R143aConstants()\n",
    "r170_class = r170.R170Constants()\n",
    "\n",
    "r41_class = r41.R41Constants()\n",
    "r23_class = r23.R23Constants()\n",
    "r161_class = r161.R161Constants()\n",
    "r152a_class = r152a.R152aConstants()\n",
    "r152_class = r152.R152Constants()\n",
    "r143_class = r143.R143Constants()\n",
    "r134_class = r134.R134Constants()\n",
    "r116_class = r116.R116Constants()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fxn(theta_guess, setup):\n",
    "    \"\"\"\n",
    "    Calculates the sse objective function\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta_guess: np.ndarray, the atom type scheme parameter set to start optimization at (sigma in nm, epsilon in kJ/mol)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    obj: float, the objective function value\n",
    "    sse_pieces: dict, dictionary of sse values for each property\n",
    "    mean_wt_pieces: dict, dictionary of mean weights for each property\n",
    "    \"\"\"\n",
    "    #  = setups\n",
    "    assert isinstance(theta_guess, np.ndarray), \"theta_guess must be an np.ndarray\"\n",
    "    # Initialize weight and squared error arrays\n",
    "    mean_array = []\n",
    "    # var_array = []\n",
    "    # var_theta = []\n",
    "\n",
    "    # Unscale data from 0 to 1 to get correct objective values\n",
    "    at_bounds_pref = setup.at_class.at_bounds_nm_kjmol\n",
    "    theta_guess = values_scaled_to_real(theta_guess.reshape(1, -1), at_bounds_pref)\n",
    "\n",
    "    # Loop over molecules\n",
    "    for molec in list(setup.molec_data_dict.keys()):\n",
    "        # Get constants for molecule\n",
    "        molec_object = setup.molec_data_dict[molec]\n",
    "        # Get theta associated with each gp\n",
    "        param_matrix = setup.at_class.get_transformation_matrix(\n",
    "            {molec: molec_object}\n",
    "        )\n",
    "        # Transform the guess, and scale to bounds\n",
    "        gp_theta = theta_guess.reshape(-1, 1).T @ param_matrix\n",
    "        gp_theta_guess = values_real_to_scaled(gp_theta, molec_object.param_bounds)\n",
    "        # Get GPs associated with each molecule\n",
    "        molec_gps_dict = setup.all_gp_dict[molec]\n",
    "\n",
    "        # Loop over gps (1 per property)\n",
    "        for key in list(molec_gps_dict.keys()):\n",
    "            # Get GP associated with property\n",
    "            gp_model = molec_gps_dict[key]\n",
    "            # Get X and Y data and bounds associated with the GP\n",
    "            exp_data, y_bounds, y_names = setup.get_exp_data(molec_object, key)\n",
    "            # Get x and y data\n",
    "            x_exp = np.array(list(exp_data.keys())).reshape(-1, 1)\n",
    "            y_exp = np.array(list(exp_data.values()))\n",
    "            # #Evaluate GP\n",
    "            gp_mean_scl, gp_covar_scl, gp_var_scl = setup.eval_gp_new_theta(\n",
    "                gp_theta_guess, molec_object, gp_model, x_exp\n",
    "            )\n",
    "            # Scale gp output to real value\n",
    "            # gp_mean = values_scaled_to_real(gp_mean_scl, y_bounds)\n",
    "            # Get y data uncertainties\n",
    "            # unc = molec_object.uncertainties[key.replace(\"sim\", \"expt\")]\n",
    "            # y_var_unc = (y_exp*unc)**2\n",
    "            # y_var_2pct = (y_exp*0.02)**2\n",
    "            # y_var = np.maximum(y_var_unc, y_var_2pct)\n",
    "            # y_std =np.sqrt(y_var)\n",
    "            # gp_mean_y_scl = gp_mean_scl.flatten()/gp_var_scl.flatten()\n",
    "            # Scale gp_variances to real values\n",
    "            # y_bounds_2D = np.asarray(y_bounds).reshape(-1,2)\n",
    "            # gp_covar = gp_covar_scl * (y_bounds_2D[:, 1] - y_bounds_2D[:, 0]) ** 2\n",
    "            # gp_var = variances_scaled_to_real(gp_var_scl, y_bounds)\n",
    "            # mean_array += list(gp_mean_y_scl)\n",
    "            # No scaling necessary since we are using the scaled values (between 0 and 1) for the objectives and parameters\n",
    "            mean_array += list(gp_mean_scl)\n",
    "            # mean_array += list(gp_mean)\n",
    "            # var_array += list(gp_var.flatten())\n",
    "    # print(\"mean array\", mean_array)\n",
    "    return np.array(mean_array)\n",
    "\n",
    "def calc_fxn_var(theta_guess, setup):\n",
    "    \"\"\"\n",
    "    Calculates the sse objective function\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta_guess: np.ndarray, the atom type scheme parameter set to start optimization at (sigma in nm, epsilon in kJ/mol)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    obj: float, the objective function value\n",
    "    sse_pieces: dict, dictionary of sse values for each property\n",
    "    mean_wt_pieces: dict, dictionary of mean weights for each property\n",
    "    \"\"\"\n",
    "    assert isinstance(theta_guess, np.ndarray), \"theta_guess must be an np.ndarray\"\n",
    "    # Initialize weight and squared error arrays\n",
    "    mean_array = []\n",
    "    var_array = []\n",
    "    # var_theta = []\n",
    "\n",
    "    # Unscale data from 0 to 1 to get correct objective values\n",
    "    at_bounds_pref = setup.at_class.at_bounds_nm_kjmol\n",
    "    theta_guess = values_scaled_to_real(theta_guess.reshape(1, -1), at_bounds_pref)\n",
    "\n",
    "    # Loop over molecules\n",
    "    for molec in list(setup.molec_data_dict.keys()):\n",
    "        # Get constants for molecule\n",
    "        molec_object = setup.molec_data_dict[molec]\n",
    "        # Get theta associated with each gp\n",
    "        param_matrix = setup.at_class.get_transformation_matrix(\n",
    "            {molec: molec_object}\n",
    "        )\n",
    "        # Transform the guess, and scale to bounds\n",
    "        gp_theta = theta_guess.reshape(-1, 1).T @ param_matrix\n",
    "        gp_theta_guess = values_real_to_scaled(gp_theta, molec_object.param_bounds)\n",
    "        # Get GPs associated with each molecule\n",
    "        molec_gps_dict = setup.all_gp_dict[molec]\n",
    "\n",
    "        # Loop over gps (1 per property)\n",
    "        for key in list(molec_gps_dict.keys()):\n",
    "            # Get GP associated with property\n",
    "            gp_model = molec_gps_dict[key]\n",
    "            # Get X and Y data and bounds associated with the GP\n",
    "            exp_data, y_bounds, y_names = setup.get_exp_data(molec_object, key)\n",
    "            # Get x and y data\n",
    "            x_exp = np.array(list(exp_data.keys())).reshape(-1, 1)\n",
    "            y_exp = np.array(list(exp_data.values()))\n",
    "            # #Evaluate GP\n",
    "            gp_mean_scl, gp_covar_scl, gp_var_scl = setup.eval_gp_new_theta(\n",
    "                gp_theta_guess, molec_object, gp_model, x_exp\n",
    "            )\n",
    "            # Scale gp output to real value\n",
    "            # gp_mean = values_scaled_to_real(gp_mean_scl, y_bounds)\n",
    "            # Get y data uncertainties\n",
    "            # unc = molec_object.uncertainties[key.replace(\"sim\", \"expt\")]\n",
    "            # y_var_unc = (y_exp*unc)**2\n",
    "            # y_var_2pct = (y_exp*0.02)**2\n",
    "            # y_var = np.maximum(y_var_unc, y_var_2pct)\n",
    "            # y_std =np.sqrt(y_var)\n",
    "            # gp_mean_y_scl = gp_mean_scl.flatten()/gp_var_scl.flatten()\n",
    "            # Scale gp_variances to real values\n",
    "            # y_bounds_2D = np.asarray(y_bounds).reshape(-1,2)\n",
    "            # gp_covar = gp_covar_scl * (y_bounds_2D[:, 1] - y_bounds_2D[:, 0]) ** 2\n",
    "            # gp_var = variances_scaled_to_real(gp_var_scl, y_bounds)\n",
    "            # mean_array += list(gp_mean_y_scl)\n",
    "            # No scaling necessary since we are using the scaled values (between 0 and 1) for the objectives and parameters\n",
    "            mean_array += list(gp_mean_scl)\n",
    "            # mean_array += list(gp_mean)\n",
    "            var_array += list(gp_var_scl.flatten())\n",
    "            # var_array += list(gp_var.flatten())\n",
    "\n",
    "    return np.array(mean_array), np.array(var_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy as copy\n",
    "repeats = 1\n",
    "seed =1\n",
    "#Get obj from a set of parameters\n",
    "at_class = 1\n",
    "obj_choice = \"ExpVal\"\n",
    "molec_names = [\"R14\", \"R32\", \"R50\", \"R170\", \"R125\", \"R134a\", \"R143a\", \"R41\"]\n",
    "setup = opt_atom_types.Opt_ATs(molec_names, at_class, repeats, seed, obj_choice)\n",
    "all_molec_dir = setup.use_dir_name\n",
    "path_best_sets = os.path.join(all_molec_dir, \"unique_best_set.csv\")\n",
    "all_df = pd.read_csv(path_best_sets, header = 0)\n",
    "first_param_name = setup.at_class.at_names[0]\n",
    "last_param_name = setup.at_class.at_names[-1]\n",
    "best_set = all_df.loc[0, first_param_name:last_param_name].values\n",
    "best_real = setup.values_pref_to_real(copy.copy(best_set))\n",
    "# rank_parameters, n_data = setup.rank_parameters(best_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def approximate_jacobian_multidimensional(f, x, setup, epsilon=1e-6):\n",
    "    \"\"\"\n",
    "    Approximate the Jacobian matrix of a vector-valued function f at a matrix-valued point x\n",
    "    using central finite differences.\n",
    "    \n",
    "    Parameters:\n",
    "    - f: callable, the function for which the Jacobian is to be computed.\n",
    "         It should accept a multidimensional array x and return a vector or matrix.\n",
    "    - x: numpy array (of any shape), the point at which the Jacobian is approximated.\n",
    "    - epsilon: float, the finite difference step size (default: 1e-6).\n",
    "    \n",
    "    Returns:\n",
    "    - J: numpy array, the approximate Jacobian. The shape will be (output_size, input_size),\n",
    "         where `output_size` is the size of f(x), and `input_size` is the size of x.\n",
    "    \"\"\"\n",
    "    # Flatten the input array to treat it as a vector\n",
    "    x_flat = x.flatten()\n",
    "    n = x_flat.size\n",
    "    f_x = np.asarray(f(x, setup))\n",
    "    m = f_x.size\n",
    "    J = np.zeros((m, n))\n",
    "\n",
    "    # Iterate over each component of the flattened x\n",
    "    for i in range(n):\n",
    "        # Perturb x at the ith flattened component\n",
    "        x_forward = np.copy(x_flat)\n",
    "        x_backward = np.copy(x_flat)\n",
    "        x_forward[i] += epsilon\n",
    "        x_backward[i] -= epsilon\n",
    "\n",
    "        # Reshape back to original shape for function evaluation\n",
    "        x_forward = x_forward.reshape(x.shape)\n",
    "        x_backward = x_backward.reshape(x.shape)\n",
    "\n",
    "        # Central difference formula\n",
    "        f_forward = np.asarray(f(x_forward, setup))\n",
    "        f_backward = np.asarray(f(x_backward, setup))\n",
    "\n",
    "        # Approximate partial derivatives\n",
    "        J[:, i] = (f_forward - f_backward) / (2 * epsilon)\n",
    "\n",
    "    return J\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_bounds_real = setup.at_class.at_bounds_nm_kjmol\n",
    "theta_guess = values_real_to_scaled(best_real.reshape(1, -1), at_bounds_real)\n",
    "print(\"theta_guess\", theta_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "def unscl_theta_calc_obj(theta_guess, setup):\n",
    "        \"\"\"\n",
    "        Wrapper function converting scaled x values from 0 to 1 to nm and kj/mol values before inputting to calc_obj\n",
    "        \"\"\"\n",
    "        assert isinstance(theta_guess, np.ndarray), \"theta_guess must be an np.ndarray\"\n",
    "        # Unscale data from 0 to 1 to get correct objective values\n",
    "        at_bounds_pref = setup.at_class.at_bounds_nm_kjmol\n",
    "        theta_guess = values_scaled_to_real(theta_guess.reshape(1, -1), at_bounds_pref)\n",
    "        obj = setup.calc_obj(theta_guess.flatten())[0]\n",
    "\n",
    "        return obj\n",
    "\n",
    "def approx_f_double_prime(theta_guess, f, setup epsilon=1e-6):\n",
    "    # First derivative\n",
    "    f_prime = lambda x: optimize.approx_fprime(theta_guess, f, epsilon)\n",
    "    # Second derivative\n",
    "    return optimize.approx_fprime(theta_guess, f_prime, epsilon)\n",
    "\n",
    "Jac = optimize.approx_fprime(theta_guess.flatten(), unscl_theta_calc_obj, np.float64(1.4901161193847656e-08), setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Jac\", Jac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z2 = np.load(\"Results/at_01/R14-R32-R50-R170-R125-R134a-R143a-R41/ExpVal/jac_approx/best_set_1.npy\")\n",
    "print(\"Z\", Z2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the parameter name asociated with each index of rank_parameters\n",
    "# rank_parameters_names = [setup.at_class.at_names[i] for i in rank_parameters]\n",
    "# print(rank_parameters_names)\n",
    "# print(n_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt_num_params, rcc, loss_k, loss_k_params = setup.estimate_opt(theta_guess, rank_parameters, n_data)\n",
    "# print(\"Optimal number of parameters: \", opt_num_params)\n",
    "# print(\"RCC: \", rcc)\n",
    "# print(\"Best Param Set: \", loss_k_params[opt_num_params-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numdifftools as nd\n",
    "\n",
    "# theta_guess = best_real\n",
    "# fun = lambda x: setup.calc_fxn(x)\n",
    "fun = calc_fxn\n",
    "dfun = nd.Gradient(fun)\n",
    "gradient = dfun(theta_guess, setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(gradient)\n",
    "gp_means, gp_vars = calc_fxn_var(theta_guess, setup)\n",
    "# print(np.sqrt(gp_vars))\n",
    "# print(gp_means.flatten())\n",
    "\n",
    "def scale_jacobian_by_x_over_F(jacobian, x, F):\n",
    "    m, n = jacobian.shape  # m = len(F), n = len(x)\n",
    "    scaled_jacobian = np.zeros_like(jacobian)\n",
    "    # print(x[0], F[0])\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            # print(x[j] / F[i], jacobian[i, j])\n",
    "            scaled_jacobian[i, j] = (x[j]/ F[i]) * jacobian[i, j]\n",
    "    \n",
    "    return scaled_jacobian\n",
    "\n",
    "# gradient_scl = scale_jacobian_by_x_over_F(gradient, theta_guess.flatten(), gp_means.flatten())\n",
    "# gradient_scl = scale_jacobian_by_x_over_F(gradient, 0.5*theta_guess.flatten(), np.sqrt(gp_vars).flatten())\n",
    "gradient_scl = gradient\n",
    "print(gradient_scl[0])\n",
    "#No scl in Jac and not div by var in calc_fxn\n",
    "# [  53.35921261    0.         -231.64743169   19.24494525    0.\n",
    "#    26.41865749]\n",
    "#No scl in Jac and mult by best_real/F\n",
    "# [ 0.48310337  0.         -2.09728833  0.17423979  0.          0.23918911]\n",
    "# Scl Jac and do not add a scaling factor\n",
    "# [ 0.91011492  0.         -4.52495685  0.684068    0.          0.99859955]\n",
    "#Scl Jac and use variance scaling factors\n",
    "# [  43.26794564    0.         -147.82845726   31.15278785    0.\n",
    "#    23.0004452 ]\n",
    "#Scl Jac and use value scaling factors\n",
    "#[ 0.59169765  0.         -2.02158317  0.42602049  0.          0.3145356 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(gradient.shape)\n",
    "# print(theta_guess)\n",
    "# print(gradient[0])\n",
    "\n",
    "# gradient_scl = gradient#*(0.5*theta_guess)\n",
    "# print(gradient_scl[0])\n",
    "# print(gradient_scl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from scipy.linalg import lstsq\n",
    "from numpy.linalg import inv\n",
    "\n",
    "def rank_parameters(Z):\n",
    "    # Step 1: Calculate the magnitude of each column in Z\n",
    "    column_magnitudes = norm(Z, axis=0)\n",
    "    print(column_magnitudes**2)\n",
    "    # print(column_magnitudes.reshape(-1,1)@column_magnitudes.reshape(-1,1).T)\n",
    "    \n",
    "    # Initialize variables\n",
    "    ranked_indices = []  # To keep track of ranked parameter indices\n",
    "    ranked_norm_vals = []\n",
    "    k = 1\n",
    "    n, m = Z.shape\n",
    "\n",
    "    while k <= m:\n",
    "        if k == 1:\n",
    "            # Step 2: Identify the most estimable parameter\n",
    "            max_index = np.argmax(column_magnitudes)\n",
    "            ranked_norm_vals.append(column_magnitudes[max_index])\n",
    "            ranked_indices.append(max_index)\n",
    "        else:\n",
    "            # Step 3: Build X_k with the k most estimable columns\n",
    "            X_k = Z[:, ranked_indices]\n",
    "\n",
    "            # Predict Z using ordinary least-squares\n",
    "            ols_est, _, _, _ = lstsq(X_k, Z) \n",
    "            Z_hat = X_k @ ols_est           \n",
    "\n",
    "            # Calculate the residual matrix R_k\n",
    "            R_k = Z - Z_hat\n",
    "\n",
    "            # Step 4: Calculate the magnitude of each column in R_k\n",
    "            residual_magnitudes = norm(R_k, axis=0)\n",
    "\n",
    "            # Step 5: Determine the next most estimable parameter\n",
    "            # Ensure we pick a column that hasn't been ranked yet\n",
    "            for idx in np.argsort(-residual_magnitudes):\n",
    "                if idx not in ranked_indices:\n",
    "                    ranked_indices.append(idx)\n",
    "                    ranked_norm_vals.append(residual_magnitudes[idx])\n",
    "                    break\n",
    "        \n",
    "        k += 1  # Step 6: Increase k and repeat\n",
    "    print(ranked_norm_vals)\n",
    "    return ranked_indices\n",
    "\n",
    "# Example usage\n",
    "Z = gradient_scl\n",
    "print(Z.shape)\n",
    "Z2 = np.load(\"Results/at_01/R14-R32-R50-R170-R125-R134a-R143a-R41/ExpVal/jac_approx/best_set_1.npy\")\n",
    "print(\"Z\", Z2)\n",
    "ranked_params = rank_parameters(Z)\n",
    "print(\"Ranked parameters (indices):\", ranked_params)\n",
    "value = [setup.at_class.at_names[param] for param in ranked_params]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define parameters\n",
    "K1, K2, K3 = 3*1e-16, 5*1e-14, 2*1e-16 # constants for x8, x9, x10 equations\n",
    "E1, E2, E_L1 = 1e4, 1e4, 1e4  # activation energies (example values)\n",
    "R = 1.986  # Gas constant (J/(mol*K))\n",
    "T, T0 = 313.15, 340.15  # Temperature (K)\n",
    "\n",
    "# Define the reaction rate constants as functions of temperature\n",
    "def k1(T):\n",
    "    k10 = 1.0  # Example pre-exponential factor\n",
    "    return k10 * np.exp(-E1 / R * (1/T - 1/T0))\n",
    "\n",
    "def k2(T):\n",
    "    k20 = 2.0  # Example pre-exponential factor\n",
    "    return k20 * np.exp(-E2 / R * (1/T - 1/T0))\n",
    "\n",
    "def k_1(T):\n",
    "    k_10 = 2000.0  # Example pre-exponential factor\n",
    "    return k_10 * np.exp(-E_L1 / R * (1/T - 1/T0))\n",
    "\n",
    "# Define the ODE system\n",
    "def system(t, X, T):\n",
    "    # print(X)\n",
    "    \n",
    "    x1, x2, x3, x4, x5, x6, x7, x8, x9, x10 = X\n",
    "    # Reaction rate constants at current temperature\n",
    "    k1_val = k1(T)\n",
    "    k2_val = k2(T)\n",
    "    k_1_val = k_1(T)\n",
    "    \n",
    "    # Define the differential equations\n",
    "    dx1dt = -k2_val * x2 * x8\n",
    "    dx2dt = -k1_val * x2 * x6 + k_1_val * x10 - k2_val * x2 * x8\n",
    "    dx3dt = k2_val * x2 * x8 + k1_val * x4 * x6 - 0.5 * k_1_val * x9\n",
    "    dx4dt = -k1_val * x4 * x6 + 0.5 * k_1_val * x9\n",
    "    dx5dt = k1_val * x2 * x6 - k_1_val * x10\n",
    "    dx6dt = -k1_val * x2 * x6 + k_1_val * x10 - k1_val * x4 * x6 + 0.5 * k_1_val * x9\n",
    "    \n",
    "    # Calculate x7, x8, x9, and x10 based on the system state\n",
    "    #How do I actually integrate with these values?\n",
    "    x7 = -0.0131 + x6 + x8 + x9 + x10\n",
    "    x8 = (K2 * x1) / (K2 + x7)\n",
    "    x9 = (K3 * x3) / (K3 + x7)\n",
    "    x10 = (K1 * x5) / (K1 + x7)\n",
    "    # print(np.array([dx1dt, dx2dt, dx3dt, dx4dt, dx5dt, dx6dt, 0,0,0,0]))\n",
    "    return np.array([dx1dt, dx2dt, dx3dt, dx4dt, dx5dt, dx6dt, 0,0,0,0])\n",
    "\n",
    "# Initial conditions\n",
    "x1 = 1.5608\n",
    "x70 = 0.5*(-K2+(K2**2+4*K2*x1)**0.5)\n",
    "X0 = [x1, 8.3546, 0.0082, 0.0086, 0.0, 0.0131, x70, x70, 0.0, 0.0]  # Example initial conditions\n",
    "\n",
    "# Time span for the simulation\n",
    "t_span = (0, 100)  # Time range in arbitrary units\n",
    "t_eval = np.linspace(0, 100, 100)\n",
    "\n",
    "# Solve the system of ODEs\n",
    "solution = solve_ivp(system, t_span, X0, args=(T,), t_eval=t_eval, method='DOP853', dense_output=False, rtol =1e-10, atol=1e-13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the solution for x1, x2, x3, and x4\n",
    "x1_sol = solution.y[0]\n",
    "print(x1_sol)\n",
    "x2_sol = solution.y[1]\n",
    "x3_sol = solution.y[2]\n",
    "x4_sol = solution.y[3]\n",
    "t_values = solution.t\n",
    "\n",
    "# Plot x1, x2, x3, and x4 as a function of time\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(t_values, x1_sol, label='x1')\n",
    "plt.plot(t_values, x2_sol, label='x2')\n",
    "plt.plot(t_values, x3_sol, label='x3')\n",
    "plt.plot(t_values, x4_sol, label='x4')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Concentration')\n",
    "plt.title('Concentration of Species x1, x2, x3, and x4 Over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hfcs-fffit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
