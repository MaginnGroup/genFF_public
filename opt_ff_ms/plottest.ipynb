{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import linregress\n",
    "# def autocorrelation(x):\n",
    "#     \"\"\"\n",
    "#     Compute autocorrelation of a time series x.\n",
    "#     \"\"\"\n",
    "#     n = len(x)\n",
    "#     variance = np.var(x)\n",
    "#     x = x - np.mean(x)\n",
    "#     autocorr_f = np.correlate(x, x, mode='full')[-n:]\n",
    "#     autocorr_f /= (variance * np.arange(n, 0, -1))\n",
    "#     return autocorr_f\n",
    "\n",
    "# Example file reading (replace with actual file)\n",
    "# Assuming the Cassandra output file contains data in a CSV format\n",
    "# with a column for the quantity of interest, say 'Energy'\n",
    "#33fa0c17dcc62689206c71f315a2bef8/prod.out.box1.prp\")) #57a003793cdd64f6b86d4472fe31f7da\n",
    "df_box1 = np.genfromtxt(\"/scratch365/mcarlozo/generalizedFF/opt_ff_ms/workspace/c9a306c8b7a1cab8fea0a0fcccf8d682/gemc.eq.out.box2.prp\")\n",
    "df_box1 = np.genfromtxt(\"/scratch365/mcarlozo/generalizedFF/opt_ff_ms/workspace/7abef0781e0e1b311fbff7bed1d8cf43/gemc.eq.out.box2.prp\")\n",
    "# df_box1 = np.genfromtxt(\"/scratch365/mcarlozo/generalizedFF/opt_ff_ms/workspace/6f3da4aec70e16d462786d82b8a77afe/prod.out.box2.prp\")\n",
    "# df_box1 = np.genfromtxt(\"/scratch365/mcarlozo/generalizedFF/opt_ff_ms/workspace/514489e76022f8180cfb413d911db92f/prod.out.box2.prp\")\n",
    "# df_box1 = np.genfromtxt(\"/scratch365/mcarlozo/generalizedFF/opt_ff_ms/workspace/38ad1aa8eb2011f713a9a22a09da9f3b/prod.out.box2.prp\")\n",
    "density_col = 6\n",
    "pressure_col = 3\n",
    "enrg_col = 2\n",
    "n_mols_col = 5\n",
    "# pull property and take average\n",
    "energy = df_box1[:, 2 - 1]\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from statistics import linear_regression\n",
    "\n",
    "\n",
    "# Generate some sample data\n",
    "data = energy\n",
    "\n",
    "# Step 1: Standardize the data\n",
    "def is_slope_zero(n, simulations_per_block, threshold=0.03):\n",
    "    # Step 1: Divide the Data\n",
    "    n_length = len(n)\n",
    "    # print(f\"Total number of data points: {n_length}\")\n",
    "\n",
    "    # Calculate the number of blocks\n",
    "    m = n_length // simulations_per_block\n",
    "    # print(f\"Number of blocks: {m}\")\n",
    "\n",
    "    # Initialize averages list\n",
    "    averages = []\n",
    "\n",
    "    for i in range(m):\n",
    "        start_index = i * simulations_per_block\n",
    "        # Handle the last block to include all remaining elements\n",
    "        end_index = n_length if i == m - 1 else (i + 1) * simulations_per_block\n",
    "        # print(f\"Block {i + 1}: Start index = {start_index}, End index = {end_index}\")\n",
    "\n",
    "        # Calculate the average of the current block\n",
    "        section_average = np.mean(n[start_index:end_index])\n",
    "        averages.append(section_average)\n",
    "\n",
    "    # Step 2: Scale the Averages between 0 and 1\n",
    "    scaler = StandardScaler()  # You can change to MinMaxScaler() if desired\n",
    "    scaled_averages = scaler.fit_transform(np.array(averages).reshape(-1, 1)).flatten()\n",
    "    \n",
    "\n",
    "    # Step 3: Divide into 5 groups\n",
    "    group_size = m // 5\n",
    "    slopes = []\n",
    "    intercepts = []\n",
    "    \n",
    "    for j in range(5):\n",
    "        group_start = j * group_size\n",
    "        group_end = (j + 1) * group_size if j < 4 else m  # Last group gets any remaining blocks\n",
    "        \n",
    "        if group_end - group_start < 2:  # Need at least two points to calculate slope\n",
    "            print(f\"Group {j + 1} has insufficient data points.\")\n",
    "            continue\n",
    "        \n",
    "        x_group = np.arange(group_start, group_end)\n",
    "        y_group = scaled_averages[group_start:group_end]\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(x_group, y_group)\n",
    "        slopes.append(slope)\n",
    "        intercepts.append(intercept)\n",
    "        print(f\"Group {j + 1}: Slope = {slope}, Intercept = {intercept}\")\n",
    "\n",
    "    # Step 3: Fit a Line with intercept fixed at 0\n",
    "    x = np.arange(m)\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(x, scaled_averages)\n",
    "    \n",
    "    # if abs(slope) > threshold:\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Original Data\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(scaler.transform(n.reshape(-1, 1)), label='Original Data', color='blue')\n",
    "    \n",
    "    # Draw vertical lines for each block average\n",
    "    for i in range(m):\n",
    "        # Calculate the x position scaled based on total number of data\n",
    "        x_position = (i * simulations_per_block + (simulations_per_block / 2))  # Middle of the block\n",
    "        plt.axvline(x=x_position, color='orange', linestyle='--', lw=0.7,\n",
    "                    label=f'Block {i + 1} Average' if i == 0 else \"\")\n",
    "    \n",
    "\n",
    "    plt.title('Original Data')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "\n",
    "    # Averages and Line of Best Fit\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(x, scaled_averages, label='Block Averages', color='orange')\n",
    "    \n",
    "    # Plot the line of best fit with intercept fixed at 0\n",
    "    plt.plot(x, slope * x + intercept, label='Line of Best Fit (Intercept = 0)', color='red')\n",
    "    plt.title('Block Averages and Line of Best Fit')\n",
    "    plt.xlabel('Block')\n",
    "    plt.ylabel('Scaled Average')\n",
    "    plt.axhline(y=0, color='k', linestyle='--', lw=0.7)  # y=0 line for reference\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Step 4: Check the Slope\n",
    "    return slope, abs(slope) < threshold\n",
    "slope, result = is_slope_zero(energy, 10)\n",
    "print(f\"The slope of the data {slope} is approximately zero: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hfcs-fffit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
